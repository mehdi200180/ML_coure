{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f42a3ce",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Introduction to Machine Learning - 25737-2</h1>\n",
    "<h4 align=\"center\">Dr. R. Amiri</h4>\n",
    "<h4 align=\"center\">Sharif University of Technology, Spring 2024</h4>\n",
    "\n",
    "\n",
    "**<font color='red'>Plagiarism is strongly prohibited!</font>**\n",
    "\n",
    "\n",
    "**Student Name**:\n",
    "\n",
    "**Student ID**:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01c559e",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "First we import libraries that we need for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0423187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import any other libraries needed below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f795731",
   "metadata": {},
   "source": [
    "## Reading Data and Preprocessing\n",
    "\n",
    "In this section, we want to read data from a CSV file and then preprocess it to make it ready for the rest of the problem.\n",
    "\n",
    "First, we read the data in the cell below and extract an $m \\times n$ matrix, $X$, and an $m \\times 1$ vector, $Y$, from it, which represent our knowledge about the features of the data (`X1`, `X2`, `X3`) and the class (`Y`), respectively. Note that by $m$, we mean the number of data points and by $n$, we mean the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "410e750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = None, None\n",
    "\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866734e2",
   "metadata": {},
   "source": [
    "Next, we should normalize our data. For normalizing a vector $\\mathbf{x}$, a very common method is to use this formula:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{norm} = \\dfrac{\\mathbf{x} - \\overline{\\mathbf{x}}}{\\sigma_\\mathbf{x}}\n",
    "$$\n",
    "\n",
    "Here, $\\overline{x}$ and $\\sigma_\\mathbf{x}$ denote the mean and standard deviation of vector $\\mathbf{x}$, respectively. Use this formula and store the new $X$ and $Y$ vectors in the cell below.\n",
    "\n",
    "**Question**: Briefly explain why we need to normalize our data before starting the training.\n",
    "\n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e757eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5465bfa4",
   "metadata": {},
   "source": [
    "Finally, we should add a column of $1$s at the beginning of $X$ to represent the bias term. Do this in the next cell. Note that after this process, $X$ should be an $m \\times (n+1)$ matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a60f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf0d78",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8714abe",
   "metadata": {},
   "source": [
    "### Sigmoid Function\n",
    "You should begin by implementing the $\\sigma(\\mathbf{x})$ function. Recall that the logistic regression hypothesis $\\mathcal{h}()$ is defined as:\n",
    "$$\n",
    "\\mathcal{h}_{\\theta}(\\mathbf{x}) = \\mathcal{g}(\\theta^\\mathbf{T}\\mathbf{x})\n",
    "$$\n",
    "where $\\mathcal{g}()$ is the sigmoid function as:\n",
    "$$\n",
    "\\mathcal{g}(\\mathbf{z}) = \\frac{1}{1+exp^{-\\mathbf{z}}}\n",
    "$$\n",
    "The Sigmoid function has the property that $\\mathbf{g}(+\\infty)\\approx 1$ and $\\mathcal{g}(−\\infty)\\approx0$. Test your function by calling `sigmoid(z)` on different test samples. Be certain that your sigmoid function works with both vectors and matrices - for either a vector or a matrix, your function should perform the sigmoid function on every element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b6ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(self, Z):\n",
    "    '''\n",
    "    Applies the sigmoid function on every element of Z\n",
    "    Arguments:\n",
    "        Z can be a (n,) vector or (n , m) matrix\n",
    "    Returns:\n",
    "        A vector/matrix, same shape with Z, that has the sigmoid function applied elementwise\n",
    "    '''\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83846074",
   "metadata": {},
   "source": [
    "### Cost Function \n",
    "Implement the functions to compute the cost function. Recall the cost function for logistic regression is a scalar value given by:\n",
    "$$\n",
    "\\mathcal{J}(\\theta) = \\sum_{i=1}^{n}[-y^{(i)}\\log{(\\mathcal{h}_\\theta(\\mathbf{x}^{(i)}))}-(1-y^{(i)})\\log{(1-\\mathcal{h}_\\theta(\\mathbf{x}^{(i)}))}] + \\frac{\\lambda}{2}||\\theta||_2^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a9bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(theta, X, y, regLambda):\n",
    "    '''\n",
    "    Computes the objective function\n",
    "    Arguments:\n",
    "        theta is d-dimensional numpy vector\n",
    "        X is a n-by-d numpy matrix\n",
    "        y is an n-dimensional numpy vector\n",
    "        regLambda is the scalar regularization constant\n",
    "    Returns:\n",
    "        a scalar value of the cost  ** make certain you're not returning a 1 x 1 matrix! **\n",
    "    '''\n",
    "    \n",
    "    m, n = X.shape\n",
    "    loss = None\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaf1146",
   "metadata": {},
   "source": [
    "### Gradient of the Cost Function\n",
    "Now, we want to calculate the gradient of the cost function. The gradient of the cost function is a d-dimensional vector.\\\n",
    "We must be careful not to regularize the $\\theta_0$ parameter (corresponding to the first feature we add to each instance), and so the 0's element is given by:\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{J}(\\theta)}{\\partial \\theta_0} = \\sum_{i=1}^n (\\mathcal{h}_\\theta(\\mathbf{x}^{(i)})-y^{(i)})\n",
    "$$\n",
    "\n",
    "Question: What is the answer to this problem for the $j^{th}$ element (for $j=1...d$)?\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f7c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeGradient(theta, X, y, regLambda):\n",
    "    '''\n",
    "    Computes the gradient of the objective function\n",
    "    Arguments:\n",
    "        theta is d-dimensional numpy vector\n",
    "        X is a n-by-d numpy matrix\n",
    "        y is an n-dimensional numpy vector\n",
    "        regLambda is the scalar regularization constant\n",
    "    Returns:\n",
    "        the gradient, an d-dimensional vector\n",
    "    '''\n",
    "    \n",
    "    m, n = X.shape\n",
    "    grad = None\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bc86bd",
   "metadata": {},
   "source": [
    "### Training and Prediction\n",
    "Once you have the cost and gradient functions complete, implemen tthe fit and predict methods.\\\n",
    "Your fit method should train the model via gradient descent, relying on the cost and gradient functions. This function should return two parameters. The first parameter is $\\theta$, and the second parameter is a `numpy` array that contains the loss in each iteration. This array is indicated by `loss_history` in the code.\\\n",
    "Instead of simply running gradient descent for a specific number of iterations, we will use a more sophisticated method: we will stop it after the solution hasconverged. Stop the gradient descent procedure when $\\theta$ stops changing between consecutive iterations. You can detect this convergence when:\n",
    "$$\n",
    "||\\theta_{new}-\\theta_{old}||_2 <= \\epsilon,\n",
    "$$\n",
    "for some small $\\epsilon$ (e.g, $\\epsilon=10E-4$).\\\n",
    "For readability, we’d recommend implementing this convergence test as a dedicated function `hasConverged`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0cad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, regLambda = 0.01, alpha = 0.01, epsilon = 1e-4, maxNumIters = 100):\n",
    "    '''\n",
    "    Trains the model\n",
    "    Arguments:\n",
    "        X           is a n-by-d numpy matrix\n",
    "        y           is an n-dimensional numpy vector\n",
    "        maxNumIters is the maximum number of gradient descent iterations\n",
    "        regLambda   is the scalar regularization constant\n",
    "        epsilon     is the convergence rate\n",
    "        alpha       is the gradient descent learning rate\n",
    "    '''\n",
    "    \n",
    "    m, n = X.shape\n",
    "    theta, loss_history = None, None \n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return theta, loss_history\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hasConverged(theta_old, theta_new, epsilon):\n",
    "    '''\n",
    "    Return if the theta converged or not\n",
    "    Arguments:\n",
    "        theta_old   is the theta calculated in prevoius iteration\n",
    "        theta_new   is the theta calculated in current iteration\n",
    "        epsilon     is the convergence rate\n",
    "    '''\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb648852",
   "metadata": {},
   "source": [
    "Finally, we want to evaluate our loss for this problem. Complete the cell below to calculate and print the loss of each iteration and the final theta of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252e556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, loss_history = fit(X, Y) # calculating theta and loss of each iteration\n",
    "\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b3fab6",
   "metadata": {},
   "source": [
    "### Testing Your Implementation\n",
    "To test your logistic regression implementation, first you should use `train_test_split` function to split dataset into three parts:\n",
    "\n",
    "- 70% for the training set\n",
    "- 20% for the validation set\n",
    "- 10% for the test set\n",
    "\n",
    "Do this in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4518fe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = None, None, None, None, None, None\n",
    "\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fbe5d7",
   "metadata": {},
   "source": [
    "Then, you should complete `predict` function to find the weight vector and the loss on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c2fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "    '''\n",
    "    Use the model to predict values for each instance in X\n",
    "    Arguments:\n",
    "        theta is d-dimensional numpy vector\n",
    "        X     is a n-by-d numpy matrix\n",
    "    Returns:\n",
    "        an n-dimensional numpy vector of the predictions, the output should be binary (use h_theta > .5)\n",
    "    '''\n",
    "    \n",
    "    Y = None\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d1c02",
   "metadata": {},
   "source": [
    "Now, run the `fit` and `predict` function for different values of the learning rate and regularization constant. Plot the `loss_history` of these different values for train and test data both in the same figure.\n",
    "\n",
    "**Question**: Discuss the effect of the learning rate and regularization constant and find the best values of these parameters.\n",
    "\n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd2af382",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "  \n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11babf15",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "In this part, you will use the `GaussianNB` classifier to classify the data. You should not change the default parameters of this classifier. First, train the classifier on the training set and then find the accuracy of it on the test set.\n",
    "\n",
    "**Question**: What is the accuracy of this method on test set?\n",
    "\n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ef450fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b371657d",
   "metadata": {},
   "source": [
    "## LDA (Linear Discriminant Analysis)\n",
    "\n",
    "In this part, you will use the `LinearDiscriminantAnalysis` classifier to classify the data. You should not change the default parameters of this classifier. First, train the classifier on the training set and then find the accuracy of it on the test set.\n",
    "\n",
    "**Question**: What is the accuracy of this method on test set?\n",
    "\n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92cc8743",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47736bdf",
   "metadata": {},
   "source": [
    "## Conclution\n",
    "\n",
    "**Question**: What is the best method for classifying this dataset? What is the best accuracy on the test set?\n",
    "\n",
    "**Answer**:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
